{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_dataset_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIXY1AAeG1Rvl0fFmEbpyy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushantp58/Neural-Nets-Repo/blob/master/MNIST_dataset_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPcEbAD9twzq"
      },
      "source": [
        "Classificaiton using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
        "\n",
        "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
        "\n",
        "Some notes:\n",
        "\n",
        "    It should succeed in less than 10 epochs, so it is okay to change epochs= to 10, but nothing larger\n",
        "    When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
        "    If you add any additional variables, make sure you use the same names as the ones used in the class\n",
        "\n",
        "I've started the code for you below -- how would you finish it?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8E54Ft4UEg2"
      },
      "source": [
        "import tensorflow as tf\n",
        "from os import path, getcwd, chdir\n",
        "\n",
        "# DO NOT CHANGE THE LINE BELOW. If you are developing in a local\n",
        "# environment, then grab mnist.npz from the Coursera Jupyter Notebook\n",
        "# and place it inside a local folder and edit the path to that location\n",
        "path = f\"{getcwd()}/../tmp2/mnist.npz\"\n",
        "mnist = tf.keras.datasets.mnist\n",
        "ACC_THRESHOLD = 0.99\n",
        "LOSS_THRESHOLD = 0.01"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hft59_bLUPW0",
        "outputId": "ac688dcc-fa62-4e1f-d26d-855cf54d0e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m82xLFjfra-"
      },
      "source": [
        "## call back function to check for the loss \n",
        "class callback_(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self,epochs,logs={}):\n",
        "        if(logs.get('acc') > ACC_THRESHOLD):\n",
        "            print(\"\\n Reached 99% accuracy so cancelling training!\")\n",
        "            self.model.stop_training =  True"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E31LZsQAUS7a"
      },
      "source": [
        "# GRADED FUNCTION: train_mnist\n",
        "def train_mnist():\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "    print(y_train[0])\n",
        "    print(x_train[0])\n",
        "    x_train = x_train / 255.0\n",
        "    model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                        tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
        "                                        tf.keras.layers.Dense(10,activation=tf.nn.softmax)])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['acc'])\n",
        "    \n",
        "    # model fitting\n",
        "    history = model.fit(x_train,y_train,epochs=9,callbacks=[callbacks])\n",
        "    ### Evaluate the model on unseen data\n",
        "    model.evaluate(x_test,y_test)\n",
        "    # model fitting\n",
        "    return history.epoch, history.history['acc'][-1]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs5LEpZdXOha",
        "outputId": "f0d2d4ff-0711-441d-968f-836f5f803bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "callbacks = callback_()\n",
        "train_mnist()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "Epoch 1/9\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1998 - acc: 0.9412\n",
            "Epoch 2/9\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0788 - acc: 0.9757\n",
            "Epoch 3/9\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0509 - acc: 0.9840\n",
            "Epoch 4/9\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0371 - acc: 0.9884\n",
            "Epoch 5/9\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9914\n",
            " Reached 99% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0263 - acc: 0.9914\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 16.2501 - acc: 0.9775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4], 0.991433322429657)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUpc9n1veGxW",
        "outputId": "17935e1f-8784-4715-f3f0-0e53a179e677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%%javascript\n",
        "<!-- Save the notebook -->\n",
        "IPython.notebook.save_checkpoint();"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "<!-- Save the notebook -->\n",
              "IPython.notebook.save_checkpoint();"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}